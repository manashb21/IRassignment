{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47bd48f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import math \n",
    "import numpy as np \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "df = pd.read_csv(\"publications_data.csv\")\n",
    "\n",
    "df['doc_content'] = df['name']+ ' ' + df['doc_title'] +\" \"+ df['doc_abstract']\n",
    "df = df.dropna()\n",
    "one_word_titles = df[df['doc_title'].str.count('\\s') == 0]['doc_title']\n",
    "df = df[~df['doc_title'].isin(one_word_titles)]\n",
    "df = df.reset_index()\n",
    "df = df.drop(columns = 'index')\n",
    "\n",
    "df_final = df.drop(columns = ['doc_content'])\n",
    "\n",
    "def clean_docs(i, doc):\n",
    "    stops = stopwords.words('english')\n",
    "    words = doc.split()\n",
    "\n",
    "    final = []\n",
    "\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        word = word.replace('-', ' ')\n",
    "        if word not in stops:\n",
    "            final.append(word)\n",
    "        \n",
    "    final = \" \". join(final)\n",
    "    final = final.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    df_final.loc[i, 'doc_content'] = final\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    data = df.loc[i, 'doc_content']\n",
    "    clean_docs(i, data)\n",
    "\n",
    "documents = list(df_final['doc_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e614328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    words = word_tokenize(doc)\n",
    "    return words\n",
    "\n",
    "def index_doc(doc):\n",
    "    tok_pos = dict()\n",
    "    for t_index,token in enumerate(doc):\n",
    "        if token in tok_pos:\n",
    "            tok_pos[token].append(t_index)\n",
    "        else:\n",
    "            tok_pos[token] = [t_index]\n",
    "    return tok_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d05e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_docs = []\n",
    "for doc in documents:\n",
    "    to_app = tokenize(doc)\n",
    "    final_docs.append(to_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f75f9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21080a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = dict()\n",
    "\n",
    "for d_idx,doc in enumerate(final_docs):    \n",
    "    poslists = index_doc(doc) # get positions of each token in the doc\n",
    "    for tok,poslist in poslists.items():\n",
    "        if tok in inverted_index:\n",
    "            inverted_index[tok][d_idx] = poslist # update\n",
    "        else:\n",
    "            inverted_index[tok] = dict()\n",
    "            inverted_index[tok][d_idx] = poslist# initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f29419d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Key Value Pair of Dictionary:\n",
      "('mohamad', {0: [0], 8807: [0]})\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for key, value in inverted_index.items():\n",
    "    if counter < 5:\n",
    "        print(f\"{key}: {value}\")\n",
    "        counter += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023cd445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbee34f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
